# LLM-агент для оценки релевантности

Данный проект реализует **LLM-агента для оценки релевантности организаций** по пользовательскому запросу (сценарии поиска / карт / локального поиска).

Цель проекта — определить, является ли организация **релевантной пользовательскому запросу**, используя **многоступенчатый, cost-aware пайплайн на базе LLM**.

Проект выполнен в формате **исследовательского ноутбука** и сфокусирован на логике агентов, prompt engineering и оценке качества, а не на продакшн-деплое.

---

## Постановка задачи

Дано:

- **пользовательский запрос** (например, поисковый запрос),
- **описание организации** (название, категория, текстовые метаданные),

необходимо определить, является ли организация **релевантной** данному запросу.

Такая задача типична для:

- поисковой релевантности,
- ранжирования,
- карт и локального поиска,
- semantic matching.

---

## Ключевая идея

Вместо одного дорогостоящего вызова LLM используется **многоступенчатый пайплайн принятия решений**:

1. **Быстрая baseline-проверка**
2. **Лёгкая LLM-оценка**
3. **LLM-агент в стиле ReAct** (reasoning + принятие решения)
4. **Fallback-логика**:
   - эскалация к более мощному агенту только при необходимости
   - опциональная симуляция внешнего контекста
5. **Cost-aware контроль вычислений**

Такой подход позволяет балансировать **качество и стоимость**, что критично для реальных LLM-систем.

---

## Обзор архитектуры

Высокоуровневый пайплайн:


???????


### Характеристики агента

- ReAct-style reasoning
- Строгий формат вывода
- Контролируемая температура
- Детерминированная логика принятия решений
- Fallback между уровнями агентов

---

## Prompt Engineering

В проекте используются **явные техники prompt engineering**:

- разделение system / user prompt
- чёткие инструкции задачи
- фиксированная схема вывода
- ограничения на рассуждения
- валидация ответов модели

Промпты спроектированы для снижения галлюцинаций и обеспечения стабильных ответов.

---

## Оценка качества

- Оценка проводилась на **небольшой отложенной выборке (80 примеров)**.
- Метрика: **accuracy**
- Лучший результат: **~0.77 accuracy**
- Полноценная оценка на всём датасете намеренно не запускалась из-за **стоимости LLM-токенов**.

Такой подход отражает реальный прототипинг, где:
- сначала проверяется идея и логика управления,
- масштабирование откладывается.

---

## Используемые технологии

- **Python**
- **LLM API** (GPT-4.1-mini)
- **Prompt Engineering**
- **LLM-агенты (ReAct)**
- **Cost-aware inference logic**
- **Jupyter Notebook**

---

## Структура проекта

?????????


Вся логика (загрузка данных, агенты, оценка) содержится в ноутбуке для прозрачности и воспроизводимости.

---

## Ограничения

- Прототип в формате ноутбука (не продакшн-сервис)
- Небольшой датасет для оценки
- Отсутствие API, деплоя и мониторинга
- Ограничения по стоимости вычислений

Ограничения осознанные и соответствуют цели — **исследование логики LLM-агентов и decision pipeline**.

---
